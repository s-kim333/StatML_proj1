{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/73/a33a9a330de1ce982b78102fe4a4b426e993a745afaf9075c13c84d1abe2/xgboost-1.2.0-py3-none-macosx_10_13_x86_64.macosx_10_14_x86_64.macosx_10_15_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 259kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/anaconda3/lib/python3.7/site-packages (from xgboost) (1.3.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from xgboost) (1.17.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('/Users/mac/Desktop/Project1/partial.csv')\n",
    "Test = pd.read_csv('/Users/mac/Desktop/Project1/test.csv')\n",
    "Train = pd.read_csv('/Users/mac/Desktop/Project1/train_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           node_1   node_2\n",
      "0          540762  1912140\n",
      "1          540762  1537559\n",
      "2          540762  3091331\n",
      "3          540762  2757277\n",
      "4          540762  3237295\n",
      "...           ...      ...\n",
      "24002356  3547024  1075576\n",
      "24002357  3547024  4549841\n",
      "24002358  3547024  1135647\n",
      "24002359  3547024   807274\n",
      "24002360  3547024  3897045\n",
      "\n",
      "[24002361 rows x 2 columns]\n",
      "        Id   source     sink\n",
      "0        1  3563811  3600160\n",
      "1        2  2052043  1401960\n",
      "2        3  4517994  1690636\n",
      "3        4  1660006  4349447\n",
      "4        5   581111  1882617\n",
      "...    ...      ...      ...\n",
      "1995  1996  1461386  2341683\n",
      "1996  1997  4057755  1871227\n",
      "1997  1998  4242514  1413468\n",
      "1998  1999   555531  1290080\n",
      "1999  2000  1707829  2373045\n",
      "\n",
      "[2000 rows x 3 columns]\n",
      "         from       in  label\n",
      "0     2893327  4331696      1\n",
      "1      455376  4697286      1\n",
      "2      544230   521586      1\n",
      "3     4238001  1870577      1\n",
      "4     1249227  1024872      1\n",
      "...       ...      ...    ...\n",
      "2995  3761828  3927071      0\n",
      "2996   379350  2581788      0\n",
      "2997  2855029  1875087      0\n",
      "2998  1842133  2245436      0\n",
      "2999  3369468  2750838      0\n",
      "\n",
      "[3000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Data) #24002361 rows x 2 columns\n",
    "print(Test) #2000 rows x 3 columns\n",
    "print(Train) #4000 rows x 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2893327, 4331696],\n",
       "       [ 455376, 4697286],\n",
       "       [ 544230,  521586],\n",
       "       ...,\n",
       "       [2855029, 1875087],\n",
       "       [1842133, 2245436],\n",
       "       [3369468, 2750838]])"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#source = list(Test.source)\n",
    "#source\n",
    "#sink = list(Test.sink)\n",
    "#node_test = (source,sink)\n",
    "#node_test = np.array((source,sink)))\n",
    "node_test = np.array(Test[['source','sink']])\n",
    "node_test\n",
    "\n",
    "node_train = np.array(Train[['from','in']])\n",
    "node_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG = nx.from_pandas_edgelist(Data, \"node_1\", \"node_2\", create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all kinds of Sim\n",
    "\n",
    "def CaculateSim_1 (node_a, node_b):\n",
    "    a_in_set = set(DG.predecessors(node_a))  \n",
    "    b_in_set = set(DG.predecessors(node_b))\n",
    "\n",
    "    if len(a_in_set | b_in_set):\n",
    "        sim_1 = len(a_in_set & b_in_set)/ len(a_in_set | b_in_set)\n",
    "        return sim_1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def CaculateSim_2 (node_a, node_b):\n",
    "    a_out_set = set(DG.successors(node_a))\n",
    "    b_out_set = set(DG.successors(node_b))\n",
    "\n",
    "    if len(a_out_set | b_out_set):\n",
    "        sim_2 = len(a_out_set & b_out_set)/ len(a_out_set | b_out_set)\n",
    "        return sim_2\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def CaculateSim_3 (node_a, node_b):\n",
    "    a_in_set = set(DG.predecessors(node_a))\n",
    "    b_out_set = set(DG.successors(node_b))\n",
    "\n",
    "    if len(a_in_set | b_out_set):\n",
    "        sim_3 = len(a_in_set & b_out_set)/ len(a_in_set | b_out_set)\n",
    "        return sim_3\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def CaculateSim_4 (node_a, node_b):\n",
    "    a_out_set = set(DG.successors(node_a))\n",
    "    b_in_set = set(DG.predecessors(node_b))\n",
    "\n",
    "    if len(a_out_set | b_in_set):\n",
    "        sim_4 = len(a_out_set & b_in_set)/ len(a_out_set | b_in_set)\n",
    "        return sim_4\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1_test = []\n",
    "sim2_test = []\n",
    "sim3_test = []\n",
    "sim4_test = []\n",
    "\n",
    "for node in node_test:\n",
    "    node_a = node[0]\n",
    "    node_b = node[1]\n",
    "    sim1_test.append(CaculateSim_1(node_a,node_b))\n",
    "    sim2_test.append(CaculateSim_2(node_a,node_b))\n",
    "    sim3_test.append(CaculateSim_3(node_a,node_b))\n",
    "    sim4_test.append(CaculateSim_4(node_a,node_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1_train = []\n",
    "for node in node_train:\n",
    "    node_a = node[0]\n",
    "    node_b = node[1]\n",
    "    sim1_train.append(CaculateSim_1(node_a,node_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim2_train = []\n",
    "for node in node_train:\n",
    "    node_a = node[0]\n",
    "    node_b = node[1]\n",
    "    sim2_train.append(CaculateSim_2(node_a,node_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim3_train = []\n",
    "for node in node_train:\n",
    "    node_a = node[0]\n",
    "    node_b = node[1]\n",
    "    sim3_train.append(CaculateSim_3(node_a,node_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim4_train = []\n",
    "for node in node_train:\n",
    "    node_a = node[0]\n",
    "    node_b = node[1]\n",
    "    sim4_train.append(CaculateSim_4(node_a,node_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sim4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DG.has_edge(540762, 249357)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#authority & hub of test\n",
    "\n",
    "Ath_test = []\n",
    "Hub_test = []\n",
    "\n",
    "for node in node_test:\n",
    "    node_a = node[0]\n",
    "    node_b = node[1]\n",
    "    pre = DG.in_degree(node_b)\n",
    "    suc = DG.out_degree(node_a)\n",
    "    Ath_test.append(pre)\n",
    "    Hub_test.append(suc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ath_test) #2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "#authority & hub of train\n",
    "\n",
    "Ath_train = []\n",
    "Hub_train = []\n",
    "\n",
    "for node in node_train:\n",
    "    node_a = node[0]\n",
    "    node_b = node[1]\n",
    "    pre = DG.in_degree(node_b)\n",
    "    suc = DG.out_degree(node_a)\n",
    "    Ath_train.append(pre)\n",
    "    Hub_train.append(suc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ath_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train['from'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         from       in      sim1  sim2  sim3      sim4  ath  hub\n",
      "0     3563811  3600160  0.000000   0.0   0.0  0.000000   29   21\n",
      "1     2052043  1401960  0.000000   0.0   0.0  0.000000    9   71\n",
      "2     4517994  1690636  0.021053   0.0   0.0  0.009091   17  205\n",
      "3     1660006  4349447  0.030303   0.0   0.0  0.003711   36  505\n",
      "4      581111  1882617  0.000000   0.0   0.0  0.000000   46   18\n",
      "...       ...      ...       ...   ...   ...       ...  ...  ...\n",
      "1995  1461386  2341683  0.000000   0.0   0.0  0.000000    2   53\n",
      "1996  4057755  1871227  0.010753   0.0   0.0  0.000000   41   95\n",
      "1997  4242514  1413468  0.000000   0.0   0.0  0.000000    2   27\n",
      "1998   555531  1290080  0.000000   0.0   0.0  0.000000    3   56\n",
      "1999  1707829  2373045  0.000000   0.0   0.0  0.000000    2  244\n",
      "\n",
      "[2000 rows x 8 columns]\n",
      "         from       in      sim1     sim2      sim3      sim4  ath    hub  \\\n",
      "0     2893327  4331696  0.074627  0.00000  0.000000  0.004403   44   2237   \n",
      "1      455376  4697286  0.000000  0.00000  0.000000  0.000000    3    190   \n",
      "2      544230   521586  0.322470  0.10794  0.030209  0.009697  781  60755   \n",
      "3     4238001  1870577  0.055741  0.00000  0.000000  0.000817   78  61151   \n",
      "4     1249227  1024872  0.045322  0.00000  0.000000  0.004142   94   7421   \n",
      "...       ...      ...       ...      ...       ...       ...  ...    ...   \n",
      "2995  3761828  3927071  0.000000  0.00000  0.000000  0.000000    1      4   \n",
      "2996   379350  2581788  0.000000  0.00000  0.000000  0.000000    2     57   \n",
      "2997  2855029  1875087  0.000000  0.00000  0.000000  0.000000    3    122   \n",
      "2998  1842133  2245436  0.000000  0.00000  0.000000  0.000000    1     10   \n",
      "2999  3369468  2750838  0.010101  0.00000  0.000000  0.002674   65    310   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "2995      0  \n",
      "2996      0  \n",
      "2997      0  \n",
      "2998      0  \n",
      "2999      0  \n",
      "\n",
      "[3000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "train_all = pd.DataFrame({'from':Train['from'] ,'in':Train['in'] ,'sim1':sim1_train,'sim2':sim2_train,'sim3':sim3_train,'sim4':sim4_train,'ath':Ath_train, 'hub':Hub_train, 'label':Train['label']})\n",
    "test_df = pd.DataFrame({'from':Test['source'] ,'in':Test['sink'] ,'sim1':sim1_test,'sim2':sim2_test,'sim3':sim3_test,'sim4':sim4_test,'ath':Ath_test, 'hub':Hub_test})\n",
    "print(test_df)\n",
    "print(train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(train_all, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>in</th>\n",
       "      <th>sim1</th>\n",
       "      <th>sim2</th>\n",
       "      <th>sim3</th>\n",
       "      <th>sim4</th>\n",
       "      <th>ath</th>\n",
       "      <th>hub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1957</td>\n",
       "      <td>3845148</td>\n",
       "      <td>958295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2087</td>\n",
       "      <td>294336</td>\n",
       "      <td>2179521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1394</td>\n",
       "      <td>427805</td>\n",
       "      <td>1782146</td>\n",
       "      <td>0.031716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>70</td>\n",
       "      <td>156905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>2209891</td>\n",
       "      <td>3165228</td>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>11</td>\n",
       "      <td>4059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1098</td>\n",
       "      <td>2101710</td>\n",
       "      <td>2809754</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>124</td>\n",
       "      <td>6933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2495</td>\n",
       "      <td>4390289</td>\n",
       "      <td>736229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>439557</td>\n",
       "      <td>4340561</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>7</td>\n",
       "      <td>61739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2742</td>\n",
       "      <td>457215</td>\n",
       "      <td>732579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>4492248</td>\n",
       "      <td>2811644</td>\n",
       "      <td>0.040650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>147</td>\n",
       "      <td>17123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1178</td>\n",
       "      <td>2687552</td>\n",
       "      <td>3622120</td>\n",
       "      <td>0.170238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006272</td>\n",
       "      <td>745</td>\n",
       "      <td>25567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         from       in      sim1  sim2  sim3      sim4  ath     hub\n",
       "1957  3845148   958295  0.000000   0.0   0.0  0.000000    2    3927\n",
       "2087   294336  2179521  0.000000   0.0   0.0  0.000000    1     368\n",
       "1394   427805  1782146  0.031716   0.0   0.0  0.000083   70  156905\n",
       "1520  2209891  3165228  0.033654   0.0   0.0  0.001723   11    4059\n",
       "1098  2101710  2809754  0.408163   0.0   0.0  0.011611  124    6933\n",
       "...       ...      ...       ...   ...   ...       ...  ...     ...\n",
       "2495  4390289   736229  0.000000   0.0   0.0  0.000000    1     197\n",
       "94     439557  4340561  0.001433   0.0   0.0  0.000049    7   61739\n",
       "2742   457215   732579  0.000000   0.0   0.0  0.000000    1    1057\n",
       "1999  4492248  2811644  0.040650   0.0   0.0  0.005414  147   17123\n",
       "1178  2687552  3622120  0.170238   0.0   0.0  0.006272  745   25567\n",
       "\n",
       "[600 rows x 8 columns]"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.drop(\"label\", axis=1)\n",
    "Y_train = train_df[\"label\"]\n",
    "X_valid = valid_df.drop(\"label\", axis=1)\n",
    "Y_valid = valid_df[\"label\"]\n",
    "X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "features = [\"sim1\",\"sim2\",\"sim3\",\"sim4\"]\n",
    "\n",
    "X_train = sc.fit_transform(train_df[features]) \n",
    "\n",
    "X_valid = sc.fit_transform(valid_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268     1\n",
       "32      1\n",
       "199     1\n",
       "1488    1\n",
       "228     1\n",
       "       ..\n",
       "2763    0\n",
       "905     1\n",
       "1096    1\n",
       "235     1\n",
       "1061    1\n",
       "Name: label, Length: 2400, dtype: int64"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.33"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0,probability = True)\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict_proba(X_valid)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score as score\n",
    "classifier.score(X_train, Y_train)\n",
    "classifier = round(classifier.score(X_train, Y_train) * 100, 2)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.79"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0,probability = True)\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict_proba(X_valid)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score as score\n",
    "classifier.score(X_train, Y_train)\n",
    "classifier = round(classifier.score(X_train, Y_train) * 100, 2)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'probability'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-b20fdc54eb38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'minkowski'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_neighbors, weights, algorithm, leaf_size, p, metric, metric_params, n_jobs, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mleaf_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleaf_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mmetric_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             n_jobs=n_jobs, **kwargs)\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'probability'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2, probability = True)\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict_proba(X_valid)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score as score\n",
    "classifier.score(X_train, Y_train)\n",
    "classifier = round(classifier.score(X_train, Y_train) * 100, 2)\n",
    "classifier #99.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'probability'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-fa88ad6c8111>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'entropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'probability'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0,probability = True)\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict_prob(X_valid)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score as score\n",
    "classifier.score(X_train, Y_train)\n",
    "classifier = round(classifier.score(X_train, Y_train) * 100, 2)\n",
    "classifier #100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'probability'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-6e9b3bf5b40d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'entropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'probability'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0,probability = True)\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict(X_valid)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score as score\n",
    "classifier.score(X_train, Y_train)\n",
    "classifier = round(classifier.score(X_train, Y_train) * 100, 2)\n",
    "classifier #100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'probability'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-bed2f5c8300b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'probability'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0, probability = True)\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict_proba(X_valid)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score as score\n",
    "classifier.score(X_train, Y_train)\n",
    "classifier = round(classifier.score(X_train, Y_train) * 100, 2)\n",
    "classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:02:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { probability } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.88"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier(probability = True)\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict_proba(X_valid)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score as score\n",
    "classifier.score(X_train, Y_train)\n",
    "classifier = round(classifier.score(X_train, Y_train) * 100, 2)\n",
    "classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>in</th>\n",
       "      <th>sim1</th>\n",
       "      <th>sim2</th>\n",
       "      <th>sim3</th>\n",
       "      <th>sim4</th>\n",
       "      <th>ath</th>\n",
       "      <th>hub</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2893327</td>\n",
       "      <td>4331696</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004403</td>\n",
       "      <td>44</td>\n",
       "      <td>2237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>455376</td>\n",
       "      <td>4697286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>544230</td>\n",
       "      <td>521586</td>\n",
       "      <td>0.322470</td>\n",
       "      <td>0.10794</td>\n",
       "      <td>0.030209</td>\n",
       "      <td>0.009697</td>\n",
       "      <td>781</td>\n",
       "      <td>60755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4238001</td>\n",
       "      <td>1870577</td>\n",
       "      <td>0.055741</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>78</td>\n",
       "      <td>61151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1249227</td>\n",
       "      <td>1024872</td>\n",
       "      <td>0.045322</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>94</td>\n",
       "      <td>7421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2995</td>\n",
       "      <td>3761828</td>\n",
       "      <td>3927071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2996</td>\n",
       "      <td>379350</td>\n",
       "      <td>2581788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2997</td>\n",
       "      <td>2855029</td>\n",
       "      <td>1875087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2998</td>\n",
       "      <td>1842133</td>\n",
       "      <td>2245436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2999</td>\n",
       "      <td>3369468</td>\n",
       "      <td>2750838</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>65</td>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         from       in      sim1     sim2      sim3      sim4  ath    hub  \\\n",
       "0     2893327  4331696  0.074627  0.00000  0.000000  0.004403   44   2237   \n",
       "1      455376  4697286  0.000000  0.00000  0.000000  0.000000    3    190   \n",
       "2      544230   521586  0.322470  0.10794  0.030209  0.009697  781  60755   \n",
       "3     4238001  1870577  0.055741  0.00000  0.000000  0.000817   78  61151   \n",
       "4     1249227  1024872  0.045322  0.00000  0.000000  0.004142   94   7421   \n",
       "...       ...      ...       ...      ...       ...       ...  ...    ...   \n",
       "2995  3761828  3927071  0.000000  0.00000  0.000000  0.000000    1      4   \n",
       "2996   379350  2581788  0.000000  0.00000  0.000000  0.000000    2     57   \n",
       "2997  2855029  1875087  0.000000  0.00000  0.000000  0.000000    3    122   \n",
       "2998  1842133  2245436  0.000000  0.00000  0.000000  0.000000    1     10   \n",
       "2999  3369468  2750838  0.010101  0.00000  0.000000  0.002674   65    310   \n",
       "\n",
       "      label  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "...     ...  \n",
       "2995      0  \n",
       "2996      0  \n",
       "2997      0  \n",
       "2998      0  \n",
       "2999      0  \n",
       "\n",
       "[3000 rows x 9 columns]"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new = pd.DataFrame({'from':Train['from'] ,'in':Train['in'] ,'sim1':sim1_train,'sim2':sim2_train,'sim3':sim3_train,'sim4':sim4_train,'ath':Ath_train, 'hub':Hub_train, 'label':Train['label']})\n",
    "train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_new.drop(\"label\", axis=1)\n",
    "Y = train_new[\"label\"]\n",
    "\n",
    "features = [\"sim1\",\"sim2\",\"sim3\",\"sim4\"]\n",
    "\n",
    "sc1 = StandardScaler()\n",
    "\n",
    "X = sc1.fit_transform(X[features]) \n",
    "X_test = sc1.fit_transform(test_df[features]) \n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:02:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { probability } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:02:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { probability } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier(probability = True)\n",
    "classifier.fit(X_train, Y_train)\n",
    "classifier.fit(X, Y)\n",
    "Y_pred = classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61285967, 0.38714033],\n",
       "       [0.61285967, 0.38714033],\n",
       "       [0.01336485, 0.98663515],\n",
       "       ...,\n",
       "       [0.61285967, 0.38714033],\n",
       "       [0.61285967, 0.38714033],\n",
       "       [0.61285967, 0.38714033]], dtype=float32)"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "for a in Y_pred:\n",
    "    pred.append(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = np.array(pred)\n",
    "#ar[ar>0.5] = 0.5\n",
    "ar[ar<0.7] = ar[ar<0.7]/5\n",
    "#956个，基本确定是1\n",
    "#len(ar[ar<0.9]) #773,这就是整体的bias造成的，整体偏大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = list(Test[\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"Id\": ID,\"Predicted\": ar})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.077428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.986635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.077428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>0.077428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>0.997022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>0.851745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>0.077428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.996185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  Predicted\n",
       "0     1   0.077428\n",
       "1     2   0.077428\n",
       "2     3   0.986635\n",
       "3     4   0.998397\n",
       "4     5   0.077428\n",
       "..  ...        ...\n",
       "95   96   0.077428\n",
       "96   97   0.997022\n",
       "97   98   0.851745\n",
       "98   99   0.077428\n",
       "99  100   0.996185\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('/Users/mac/Desktop/Project1/sbm4.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
